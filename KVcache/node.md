#### 训练1个GPT模型大概要花多少钱：
llama-2-70b: 140GB文件（主要是parameters和很少的run.c），700亿参数，抓取10TB网络数据集
6000张GPU显卡训练12天，约200万美元

#### 如何回答问题
最大概率的下一个字

#### Transformer架构
见transformer笔记


